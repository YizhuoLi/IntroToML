{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47222222 0.09090909 0.52631579 0.375     ]\n",
      " [0.36111111 0.45454545 0.61403509 0.58333333]\n",
      " [0.36111111 0.22727273 0.50877193 0.41666667]\n",
      " [0.41666667 0.31818182 0.71929825 0.75      ]\n",
      " [0.33333333 0.18181818 0.49122807 0.41666667]\n",
      " [0.66666667 0.45454545 0.70175439 0.66666667]\n",
      " [0.08333333 0.72727273 0.         0.04166667]\n",
      " [0.38888889 0.36363636 0.61403509 0.5       ]\n",
      " [0.33333333 0.27272727 0.59649123 0.45833333]\n",
      " [0.38888889 0.27272727 0.43859649 0.375     ]\n",
      " [0.66666667 0.5        0.59649123 0.54166667]\n",
      " [0.55555556 0.59090909 0.64912281 0.625     ]\n",
      " [0.55555556 0.22727273 0.68421053 0.58333333]\n",
      " [0.41666667 0.31818182 0.50877193 0.45833333]\n",
      " [0.66666667 0.5        0.64912281 0.58333333]\n",
      " [0.41666667 0.31818182 0.71929825 0.75      ]\n",
      " [0.30555556 0.63636364 0.12280702 0.04166667]\n",
      " [0.16666667 0.22727273 0.61403509 0.66666667]\n",
      " [0.94444444 0.45454545 0.89473684 0.91666667]\n",
      " [0.19444444 0.68181818 0.10526316 0.20833333]\n",
      " [0.47222222 0.31818182 0.71929825 0.625     ]\n",
      " [0.58333333 0.54545455 0.75438596 0.91666667]\n",
      " [0.41666667 0.27272727 0.52631579 0.45833333]\n",
      " [0.19444444 0.72727273 0.07017544 0.04166667]\n",
      " [0.16666667 0.5        0.0877193  0.        ]\n",
      " [0.61111111 0.36363636 0.63157895 0.58333333]\n",
      " [0.77777778 0.45454545 0.85964912 0.83333333]\n",
      " [0.72222222 0.5        0.77192982 0.83333333]\n",
      " [0.02777778 0.40909091 0.07017544 0.04166667]\n",
      " [0.         0.45454545 0.01754386 0.        ]\n",
      " [0.30555556 0.86363636 0.12280702 0.125     ]\n",
      " [0.33333333 1.         0.07017544 0.04166667]\n",
      " [0.30555556 0.63636364 0.0877193  0.125     ]\n",
      " [0.25       0.31818182 0.50877193 0.54166667]\n",
      " [0.47222222 0.09090909 0.70175439 0.58333333]\n",
      " [0.5        0.40909091 0.64912281 0.54166667]\n",
      " [0.58333333 0.36363636 0.80701754 0.875     ]\n",
      " [0.66666667 0.59090909 0.8245614  1.        ]\n",
      " [0.66666667 0.5        0.80701754 0.95833333]\n",
      " [0.61111111 0.45454545 0.73684211 0.79166667]\n",
      " [0.02777778 0.54545455 0.05263158 0.04166667]\n",
      " [0.38888889 0.36363636 0.54385965 0.5       ]\n",
      " [0.19444444 0.68181818 0.05263158 0.08333333]\n",
      " [0.41666667 0.90909091 0.03508772 0.04166667]\n",
      " [0.86111111 0.36363636 0.89473684 0.75      ]\n",
      " [0.22222222 0.81818182 0.15789474 0.125     ]\n",
      " [0.08333333 0.63636364 0.07017544 0.08333333]\n",
      " [0.36111111 0.31818182 0.56140351 0.5       ]\n",
      " [0.13888889 0.63636364 0.15789474 0.04166667]\n",
      " [0.44444444 0.54545455 0.66666667 0.70833333]\n",
      " [0.72222222 0.5        0.71929825 0.91666667]\n",
      " [0.22222222 0.59090909 0.12280702 0.16666667]\n",
      " [0.38888889 0.81818182 0.12280702 0.08333333]\n",
      " [0.36111111 0.36363636 0.68421053 0.79166667]\n",
      " [0.22222222 0.81818182 0.10526316 0.04166667]\n",
      " [0.80555556 0.72727273 0.89473684 1.        ]\n",
      " [0.69444444 0.54545455 0.85964912 0.91666667]\n",
      " [0.61111111 0.45454545 0.78947368 0.70833333]\n",
      " [0.38888889 0.45454545 0.56140351 0.45833333]\n",
      " [0.80555556 0.45454545 0.84210526 0.625     ]\n",
      " [0.66666667 0.45454545 0.73684211 0.91666667]\n",
      " [0.25       0.68181818 0.0877193  0.04166667]\n",
      " [0.58333333 0.5        0.78947368 0.70833333]\n",
      " [0.55555556 0.22727273 0.70175439 0.75      ]\n",
      " [0.47222222 0.63636364 0.61403509 0.625     ]\n",
      " [0.80555556 0.54545455 0.87719298 0.70833333]\n",
      " [0.19444444 0.63636364 0.10526316 0.125     ]\n",
      " [0.11111111 0.54545455 0.10526316 0.04166667]\n",
      " [0.19444444 0.45454545 0.10526316 0.04166667]\n",
      " [0.83333333 0.40909091 0.92982456 0.70833333]\n",
      " [0.05555556 0.13636364 0.05263158 0.08333333]\n",
      " [0.55555556 0.63636364 0.80701754 0.95833333]\n",
      " [0.08333333 0.5        0.0877193  0.04166667]\n",
      " [0.58333333 0.36363636 0.80701754 0.83333333]\n",
      " [0.33333333 0.13636364 0.52631579 0.5       ]\n",
      " [0.61111111 0.45454545 0.84210526 0.875     ]\n",
      " [0.08333333 0.54545455 0.07017544 0.04166667]\n",
      " [0.30555556 0.45454545 0.61403509 0.58333333]\n",
      " [0.44444444 0.45454545 0.56140351 0.58333333]\n",
      " [0.19444444 0.63636364 0.0877193  0.04166667]\n",
      " [0.66666667 0.59090909 0.8245614  0.83333333]\n",
      " [0.25       0.63636364 0.07017544 0.04166667]\n",
      " [0.44444444 0.45454545 0.71929825 0.70833333]\n",
      " [0.72222222 0.5        0.68421053 0.58333333]\n",
      " [0.27777778 0.77272727 0.0877193  0.04166667]\n",
      " [0.55555556 0.36363636 0.71929825 0.58333333]\n",
      " [0.5        0.36363636 0.64912281 0.45833333]\n",
      " [0.69444444 0.45454545 0.78947368 0.83333333]\n",
      " [0.19444444 0.         0.43859649 0.375     ]\n",
      " [0.58333333 0.40909091 0.57894737 0.5       ]\n",
      " [0.25       0.95454545 0.0877193  0.        ]\n",
      " [1.         0.81818182 0.94736842 0.79166667]\n",
      " [0.33333333 0.68181818 0.05263158 0.04166667]\n",
      " [0.94444444 0.81818182 1.         0.875     ]\n",
      " [0.63888889 0.45454545 0.59649123 0.54166667]\n",
      " [0.16666667 0.5        0.0877193  0.        ]\n",
      " [0.58333333 0.31818182 0.75438596 0.75      ]\n",
      " [0.33333333 0.22727273 0.52631579 0.5       ]\n",
      " [0.55555556 0.31818182 0.68421053 0.70833333]\n",
      " [0.5        0.45454545 0.68421053 0.70833333]\n",
      " [0.19444444 0.54545455 0.03508772 0.04166667]\n",
      " [0.52777778 0.63636364 0.77192982 0.91666667]\n",
      " [0.55555556 0.13636364 0.59649123 0.5       ]\n",
      " [0.61111111 0.54545455 0.71929825 0.79166667]\n",
      " [0.5        0.45454545 0.63157895 0.54166667]\n",
      " [0.58333333 0.54545455 0.61403509 0.58333333]\n",
      " [0.30555556 0.86363636 0.05263158 0.125     ]\n",
      " [0.63888889 0.40909091 0.63157895 0.5       ]\n",
      " [0.22222222 0.77272727 0.0877193  0.125     ]\n",
      " [0.19444444 0.59090909 0.07017544 0.04166667]\n",
      " [0.36111111 0.40909091 0.45614035 0.5       ]\n",
      " [0.52777778 0.09090909 0.61403509 0.58333333]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNumNeighborsVsAccuracy(P_value=2, metric_value='minkowski'):\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    neighbor_settings = range(1,11)\n",
    "    for curKvalue in neighbor_settings:\n",
    "        # build the model\n",
    "        clf = KNeighborsClassifier(n_neighbors=curKvalue, p=P_value, metric=metric_value)\n",
    "        clf.fit(X_train_norm, y_train)\n",
    "        # Record training set accuracy\n",
    "        curTrainAccuracy = clf.score(X_train_norm, y_train)\n",
    "        training_accuracy.append(curTrainAccuracy)\n",
    "        # Record test set accuracy\n",
    "        curTestAccuracy = clf.score(X_test_norm, y_test)\n",
    "        test_accuracy.append(curTestAccuracy)\n",
    "    plt.plot(neighbor_settings, training_accuracy, label='Training accuracy')\n",
    "    plt.plot(neighbor_settings, test_accuracy, label='Test accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('number of neighbor')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2b3e635466fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotNumNeighborsVsAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-31cf6d959968>\u001b[0m in \u001b[0;36mplotNumNeighborsVsAccuracy\u001b[0;34m(P_value, metric_value)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcurTestAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurTestAccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbor_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbor_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "plotNumNeighborsVsAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotNumNeighborsVsAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Transform scale of data\n",
    "ss= StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "#Train and evaluate the linear SVM\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "curTestAccuracy = svm_clf.score(X_test_scaled, y_test)\n",
    "print(curTestAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "poly_kernal_svm_clf = SVC(kernel='poly', degree=3)\n",
    "poly_kernal_svm_clf.fit(X_train_scaled, y_train)\n",
    "curTestAccuracy = poly_kernal_svm_clf.score(X_test_scaled, y_test)\n",
    "print(curTestAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:\n",
      "[0. 0. 0.]\n",
      "Average cross-validation score: 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kflod = KFold(n_splits=3)\n",
    "fold_accuracies = cross_val_score(svm_clf, X, y, cv=kflod)\n",
    "print('Cross validation score:\\n{}'.format(fold_accuracies))\n",
    "print('Average cross-validation score: {:.2f}'.format(fold_accuracies.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:\n",
      "[0.94 0.98 0.94]\n",
      "Average cross-validation score: 0.95\n"
     ]
    }
   ],
   "source": [
    "kflod = KFold(n_splits=3, shuffle=True, random_state=2)\n",
    "fold_accuracies = cross_val_score(svm_clf, X, y, cv=kflod)\n",
    "print('Cross validation score:\\n{}'.format(fold_accuracies))\n",
    "print('Average cross-validation score: {:.2f}'.format(fold_accuracies.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True hyperparameter using cross_validation\n",
    "best_score = 0\n",
    "for curC in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    svm = SVC(C=curC)\n",
    "    fold_accuracy = cross_val_score(svm, X_train, y_train)\n",
    "    score = fold_accuracies.mean()\n",
    "    if score > best_score:\n",
    "        best_param = {'C': curC}\n",
    "        best_score = score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
