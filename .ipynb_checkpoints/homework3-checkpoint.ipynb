{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi Professor, I done the homework by code to finish the calculate. If there are something unclear, please tell me. Thanks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing, there are something wrong with the picture in the jupyter notebook. It can't be shown at the perfect location. So, I just put it at the top. Thanks for you understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[600, 'yes', 'yes'],\n",
    "               [400, 'no', 'yes'],\n",
    "               [500, 'no', 'yes'],\n",
    "               [1000, 'yes', 'no'],\n",
    "               [700, 'no', 'no'],\n",
    "               [1200, 'yes', 'no'],\n",
    "               [800, 'yes', 'yes'],\n",
    "               [600, 'no', 'yes']]\n",
    "    labels = ['Rent','Clean']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[600, 'yes', 'yes'],\n",
       " [400, 'no', 'yes'],\n",
       " [500, 'no', 'yes'],\n",
       " [1000, 'yes', 'no'],\n",
       " [700, 'no', 'no'],\n",
       " [1200, 'yes', 'no'],\n",
       " [800, 'yes', 'yes'],\n",
       " [600, 'no', 'yes']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData,labels=createDataSet()\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the entyopy，了解信息的混乱程度，为选择划分标准做准备\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    #creat dict for all poaaible classifier\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0 # initial value 0\n",
    "        labelCounts[currentLabel] += 1# count how many currentLabels\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries # use dict[key] to access ditc\n",
    "        #cal log\n",
    "        shannonEnt -= prob * log(prob,2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9544340029249649"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcShannonEnt(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate different feature of the dataset, we need to split the dataset first\n",
    "# axis is the feature we will split(chop)，value is what we want to split(get)\n",
    "def splitDataSet_str(dataSet, axis, value):\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]     #chop out axis used for splitting\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "\n",
    "def splitDataSet_int(dataSet, axis, value):\n",
    "    retDataSet_S = []\n",
    "    retDataSet_L = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] <= value:\n",
    "            reducedFeatVec = featVec[:axis]     #chop out axis used for splitting\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet_S.append(reducedFeatVec)\n",
    "        if featVec[axis] > value:\n",
    "            reducedFeatVec = featVec[:axis]     #chop out axis used for splitting\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet_L.append(reducedFeatVec)\n",
    "    return retDataSet_S, retDataSet_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the best feature to split\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1      #the last column is used for the labels\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain = 0.0; bestFeature = -1\n",
    "    for i in range(numFeatures):        #iterate over all the features\n",
    "        featList = [example[i] for example in dataSet]# create a list of all the examples of this feature\n",
    "        uniqueVals = set(featList)       # get a set of unique values\n",
    "        print(uniqueVals)\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            if type(value)==str:\n",
    "                subDataSet = splitDataSet_str(dataSet, i, value)\n",
    "                prob = len(subDataSet)/float(len(dataSet))\n",
    "                lineEntropy = prob * calcShannonEnt(subDataSet)\n",
    "                newEntropy += lineEntropy\n",
    "#                 print('the entropy of ', value, ' is', lineEntropy)\n",
    "                infoGain = baseEntropy - newEntropy     #calculate the info gain; ie reduction in entropy\n",
    "                print('The IG of label ', i,' is', infoGain)\n",
    "            else:\n",
    "                subDataSet1, subDataSet2 = splitDataSet_int(dataSet, i, value)\n",
    "                prob1 = len(subDataSet1)/float(len(dataSet))\n",
    "                prob2 = len(subDataSet2)/float(len(dataSet))\n",
    "                lineEntropy_S = prob1 * calcShannonEnt(subDataSet1)\n",
    "                lineEntropy_L = prob2 * calcShannonEnt(subDataSet2)\n",
    "                lineEntropy = lineEntropy_S+lineEntropy_L\n",
    "#                 print('the entropy of ', value, ' is', lineEntropy)\n",
    "                infoGain = baseEntropy - lineEntropy     #calculate the info gain; ie reduction in entropy\n",
    "                print('the IG of ', value, ' is', infoGain)\n",
    "\n",
    "#         if (infoGain > bestInfoGain):       #compare this to the best gain so far\n",
    "#             bestInfoGain = infoGain         #if better than current best, set to best\n",
    "#             bestFeature = value\n",
    "#     return bestFeature                      #returns an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{800, 1000, 400, 1200, 500, 600, 700}\n",
      "the IG of  800  is 0.46691718668869936\n",
      "the IG of  1000  is 0.19920350542916276\n",
      "the IG of  400  is 0.09235938389499476\n",
      "the IG of  1200  is 0.0\n",
      "the IG of  500  is 0.20443400292496494\n",
      "the IG of  600  is 0.5487949406953985\n",
      "the IG of  700  is 0.15886800584992988\n",
      "{'no', 'yes'}\n",
      "The IG of label  1  is 0.5487949406953985\n",
      "The IG of label  1  is 0.04879494069539847\n"
     ]
    }
   ],
   "source": [
    "chooseBestFeatureToSplit(trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IG of label 1 is the last valuse. So, from the IG we calculated above, the biggest IG is IG(600). So the top of our tree is whether the rent bigger than (700+600)/2=650. Why we use the mean is we need the value bigger than 600 and smaller than the next value.  \n",
    "Then the left of the tree is all the sastified. So we finished the classification of left tree.  \n",
    "Then we should drop the data of the left tree and then calculate the IG of the right tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1000, 'yes', 'no'],\n",
       " [700, 'no', 'no'],\n",
       " [1200, 'yes', 'no'],\n",
       " [800, 'yes', 'yes']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData_2 = []\n",
    "for value in trainData:\n",
    "    if value[0]>650:\n",
    "        trainData_2.append(value)\n",
    "trainData_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1000, 800, 700, 1200}\n",
      "the IG of  1000  is 0.12255624891826566\n",
      "the IG of  800  is 0.31127812445913283\n",
      "the IG of  700  is 0.12255624891826566\n",
      "the IG of  1200  is 0.0\n",
      "{'no', 'yes'}\n",
      "The IG of label  1  is 0.8112781244591328\n",
      "The IG of label  1  is 0.12255624891826566\n"
     ]
    }
   ],
   "source": [
    "chooseBestFeatureToSplit(trainData_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IG of label 1 is the last valuse. So, from the IG we calculated above, the biggest IG is IG(800). So the first node of our right tree is whether the rent bigger than (800+1000)/2=900.  \n",
    "Then the right of the right tree is all unsastified. So we finished the classification of the right of the right tree.  \n",
    "Then we should drop the data of the right of the right tree and then calculate the IG of the data left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[700, 'no', 'no'], [800, 'yes', 'yes']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData_3 = []\n",
    "for value in trainData_2:\n",
    "    if value[0]<900:\n",
    "        trainData_3.append(value)\n",
    "trainData_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{800, 700}\n",
      "the IG of  800  is 0.0\n",
      "the IG of  700  is 1.0\n",
      "{'no', 'yes'}\n",
      "The IG of label  1  is 1.0\n",
      "The IG of label  1  is 1.0\n"
     ]
    }
   ],
   "source": [
    "chooseBestFeatureToSplit(trainData_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the IG above, we could know that we could either use the label of 'clean' or whether the rent is greater than 750. However, as a human, I know if the room is clean, we should be more sastified than not clean. So, I prefer to choose that when the rent is bigger than 650 and smaller than 900. When the room is clean, we will be satisfied. But if the room is not clean, we will be unsatisfied. So, my tree will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ![jupyter](./Decision_Tree.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the result of the predict should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTestSet():\n",
    "    dataSet = [[550, 'no', 'yes'],\n",
    "               [750, 'yes', 'yes'],\n",
    "               [850, 'no', 'no'],\n",
    "               [1000, 'yes', 'yes']]\n",
    "    return dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[550, 'no', 'yes'],\n",
       " [750, 'yes', 'yes'],\n",
       " [850, 'no', 'no'],\n",
       " [1000, 'yes', 'yes']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData=createTestSet()\n",
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ['yes', 'yes', 'no', 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predict result of  [550, 'no', 'yes'] is  yes\n",
      "The predict result of  [750, 'yes', 'yes'] is  yes\n",
      "The predict result of  [850, 'no', 'no'] is  no\n",
      "The predict result of  [1000, 'yes', 'yes'] is  no\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,4):\n",
    "    print('The predict result of ', testData[i], 'is ', result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the presion of the prediction is 100% and the recall of the prediction is 50%.(The true position is predicted and true is 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix is shown as belowL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x116537668>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "array = [[1,0], \n",
    "        [1,2]]\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"01\"],\n",
    "                  columns = [i for i in \"01\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the code to see whether it's the same with the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_giniIndex = DecisionTreeClassifier(criterion='entropy', max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[600, 'yes'],\n",
       " [400, 'no'],\n",
       " [500, 'no'],\n",
       " [1000, 'yes'],\n",
       " [700, 'no'],\n",
       " [1200, 'yes'],\n",
       " [800, 'yes'],\n",
       " [600, 'no']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "for X in trainData:\n",
    "    X_train.append(X[:2])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['yes'], ['yes'], ['yes'], ['no'], ['no'], ['no'], ['yes'], ['yes']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = []\n",
    "for y in trainData:\n",
    "    y_train.append(y[2:])\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[600, 1],\n",
       " [400, 0],\n",
       " [500, 0],\n",
       " [1000, 1],\n",
       " [700, 0],\n",
       " [1200, 1],\n",
       " [800, 1],\n",
       " [600, 0]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in X_train:\n",
    "    if x[1]=='yes':\n",
    "        x[1] = 1\n",
    "    else:\n",
    "        x[1] = 0\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [1], [1], [0], [0], [0], [1], [1]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for y in y_train:\n",
    "    if y[0]=='yes':\n",
    "        y[0]=1\n",
    "    else:\n",
    "        y[0]=0\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_giniIndex.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"236pt\" height=\"314pt\"\n",
       " viewBox=\"0.00 0.00 236.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-310 232,-310 232,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.400000\" stroke=\"#000000\" d=\"M123,-306C123,-306 57,-306 57,-306 51,-306 45,-300 45,-294 45,-294 45,-235 45,-235 45,-229 51,-223 57,-223 57,-223 123,-223 123,-223 129,-223 135,-229 135,-235 135,-235 135,-294 135,-294 135,-300 129,-306 123,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"90\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">Rent &lt;= 650.0</text>\n",
       "<text text-anchor=\"middle\" x=\"90\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.954</text>\n",
       "<text text-anchor=\"middle\" x=\"90\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8</text>\n",
       "<text text-anchor=\"middle\" x=\"90\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 5]</text>\n",
       "<text text-anchor=\"middle\" x=\"90\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = a</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#399de5\" stroke=\"#000000\" d=\"M66,-179.5C66,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 66,-111.5 66,-111.5 72,-111.5 78,-117.5 78,-123.5 78,-123.5 78,-167.5 78,-167.5 78,-173.5 72,-179.5 66,-179.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"39\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"39\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"39\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 4]</text>\n",
       "<text text-anchor=\"middle\" x=\"39\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = a</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M72.1627,-222.8796C67.4972,-211.9935 62.4544,-200.227 57.7433,-189.2344\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"60.8627,-187.6277 53.7064,-179.8149 54.4286,-190.3851 60.8627,-187.6277\"/>\n",
       "<text text-anchor=\"middle\" x=\"44.4216\" y=\"-199.3269\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.666667\" stroke=\"#000000\" d=\"M174,-187C174,-187 108,-187 108,-187 102,-187 96,-181 96,-175 96,-175 96,-116 96,-116 96,-110 102,-104 108,-104 108,-104 174,-104 174,-104 180,-104 186,-110 186,-116 186,-116 186,-175 186,-175 186,-181 180,-187 174,-187\"/>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">Rent &lt;= 900.0</text>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.811</text>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 1]</text>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = S</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M107.8373,-222.8796C111.4656,-214.4136 115.322,-205.4153 119.0732,-196.6626\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"122.3643,-197.8683 123.0865,-187.2981 115.9303,-195.1108 122.3643,-197.8683\"/>\n",
       "<text text-anchor=\"middle\" x=\"132.3713\" y=\"-206.81\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"transparent\" stroke=\"#000000\" d=\"M120,-68C120,-68 66,-68 66,-68 60,-68 54,-62 54,-56 54,-56 54,-12 54,-12 54,-6 60,0 66,0 66,0 120,0 120,0 126,0 132,-6 132,-12 132,-12 132,-56 132,-56 132,-62 126,-68 120,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"93\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.0</text>\n",
       "<text text-anchor=\"middle\" x=\"93\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"93\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 1]</text>\n",
       "<text text-anchor=\"middle\" x=\"93\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = S</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M123.1266,-103.9815C119.4074,-95.3423 115.478,-86.2144 111.729,-77.5059\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"114.9192,-76.0648 107.7503,-68.2637 108.4897,-78.8327 114.9192,-76.0648\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M216,-68C216,-68 162,-68 162,-68 156,-68 150,-62 150,-56 150,-56 150,-12 150,-12 150,-6 156,0 162,0 162,0 216,0 216,0 222,0 228,-6 228,-12 228,-12 228,-56 228,-56 228,-62 222,-68 216,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = S</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M158.8734,-103.9815C162.5926,-95.3423 166.522,-86.2144 170.271,-77.5059\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.5103,-78.8327 174.2497,-68.2637 167.0808,-76.0648 173.5103,-78.8327\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x117111a90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dot_data = tree.export_graphviz(tree_giniIndex, out_file = None,\n",
    "                              feature_names = labels,\n",
    "                              class_names = 'Satisfied',\n",
    "                              filled = True,\n",
    "                              rounded = True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, we could say it's exactly same with my tree. Now I am satisfied.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[550, 'no'], [750, 'yes'], [850, 'no'], [1000, 'yes']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = []\n",
    "for X in testData:\n",
    "    X_test.append(X[:2])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['yes'], ['yes'], ['no'], ['yes']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = []\n",
    "for y in testData:\n",
    "    y_test.append(y[2:])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[550, 0], [750, 1], [850, 0], [1000, 1]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in X_test:\n",
    "    if x[1]=='yes':\n",
    "        x[1] = 1\n",
    "    else:\n",
    "        x[1] = 0\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [1], [0], [1]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for y in y_test:\n",
    "    if y[0]=='yes':\n",
    "        y[0]=1\n",
    "    else:\n",
    "        y[0]=0\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = []\n",
    "for y in y_test:\n",
    "    y_true.append(y[0])\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = tree_giniIndex.predict(X_test)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.33      0.50         3\n",
      "          1       0.33      1.00      0.50         1\n",
      "\n",
      "avg / total       0.83      0.50      0.50         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_predicted, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the report above we could know the precision and the recall of the prediction is not same with my tree. I am not sure what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68,0.5,'predict lable')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mat = confusion_matrix(y_true, y_predicted)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predict lable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, we could see the same result is different from the report above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes : ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, same with decision tree, we build our own model first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[600], [400], [500], [1000], [700], [1200], [800], [600]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rentTrain = []\n",
    "for X in trainData:\n",
    "    X_rentTrain.append(X[:1])\n",
    "X_rentTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of (Rent | like) is  580.0\n",
      "The std of (Rent | like) is  132.664991614216\n",
      "The mean of (Rent | dislike) is  966.6666666666666\n",
      "The std of (Rent | dislike) is  205.48046676563254\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_rentTrainLike = []\n",
    "X_rentTrainUnlike = []\n",
    "for x in trainData:\n",
    "    if x[2]=='yes':\n",
    "        X_rentTrainLike.append(x[0])\n",
    "    else:\n",
    "        X_rentTrainUnlike.append(x[0])\n",
    "\n",
    "mean_Like = np.mean(X_rentTrainLike)\n",
    "std_Like = np.std(X_rentTrainLike)\n",
    "mean_unLike = np.mean(X_rentTrainUnlike)\n",
    "std_unLike = np.std(X_rentTrainUnlike)\n",
    "\n",
    "print('The mean of (Rent | like) is ', mean_Like)\n",
    "print('The std of (Rent | like) is ', std_Like)\n",
    "print('The mean of (Rent | dislike) is ', mean_unLike)\n",
    "print('The std of (Rent | dislike) is ', std_unLike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def normpdf(x, mean, sd):\n",
    "    var = float(sd)**2\n",
    "    denom = (2*math.pi*var)**.5\n",
    "    num = math.exp(-(float(x)-float(mean))**2/(2*var))\n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[550, 'no', 'yes']\n",
      "P(Rent | like) is 0.0029312280750170548\n",
      "P(Rent | dislike) is 0.00024846450416328994\n",
      "P(like | Rent) is 0.0018320175468856592\n",
      "P(dislike | Rent) is 9.317418906123372e-05\n",
      "[550, 'no', 'yes'] Yes\n",
      "[750, 'yes', 'yes']\n",
      "P(Rent | like) is 0.0013230860545007733\n",
      "P(Rent | dislike) is 0.001113540652675583\n",
      "P(like | Rent) is 0.0008269287840629833\n",
      "P(dislike | Rent) is 0.0004175777447533436\n",
      "[750, 'yes', 'yes'] Yes\n",
      "[850, 'no', 'no']\n",
      "P(Rent | like) is 0.0003790705012732947\n",
      "P(Rent | dislike) is 0.0016524872184977863\n",
      "P(like | Rent) is 0.00023691906329580917\n",
      "P(dislike | Rent) is 0.0006196827069366699\n",
      "[850, 'no', 'no'] No\n",
      "[1000, 'yes', 'yes']\n",
      "P(Rent | like) is 2.0033007694342812e-05\n",
      "P(Rent | dislike) is 0.0019161306647508657\n",
      "P(like | Rent) is 1.2520629808964257e-05\n",
      "P(dislike | Rent) is 0.0007185489992815746\n",
      "[1000, 'yes', 'yes'] No\n"
     ]
    }
   ],
   "source": [
    "for value in testData:\n",
    "    P_like = normpdf(value[0], mean_Like, std_Like)\n",
    "    P_dislike = normpdf(value[0], mean_unLike, std_unLike)\n",
    "    print(value)\n",
    "    print('P(Rent | like) is', P_like)\n",
    "    print('P(Rent | dislike) is', P_dislike)\n",
    "    print('P(like | Rent) is', P_like*5/8)\n",
    "    print('P(dislike | Rent) is', P_dislike*3/8)\n",
    "    if P_like*5/8>P_dislike*3/8:\n",
    "        print(value, \"Yes\")\n",
    "    else:\n",
    "        print(value, \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above, we could know that the result is same with my tree result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11723e358>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "array = [[1,0], \n",
    "        [1,2]]\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"01\"],\n",
    "                  columns = [i for i in \"01\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let us see the performance of the algorithorm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[550], [750], [850], [1000]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rentTest = []\n",
    "for X in testData:\n",
    "    X_rentTest.append(X[:1])\n",
    "X_rentTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67         2\n",
      "          1       0.67      1.00      0.80         2\n",
      "\n",
      "avg / total       0.83      0.75      0.73         4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhuoli/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussian_model = GaussianNB()\n",
    "gaussian_model.fit(X_rentTrain, y_train)\n",
    "y_predictedNB = gaussian_model.predict(X_rentTest)\n",
    "print(metrics.classification_report(y_predictedNB, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68,0.5,'true lable')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEKCAYAAADqyxvJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADQ1JREFUeJzt3X+QnAV9x/HP53JVJCTMRBAICeRCMEhoKFPI8MNpTSeIKJqMYgDF0koN1oQQaBEqDjMoHduZYEFT0UiZMK0SgTqCiLQDKgpSuGsNgSS0EUnNLwIRhBBoIfDtH/dc2Tlz+30u5tnnSe79mrm53Wef3ec7hHnfs88+u+uIEAC001X3AACaj1AASBEKAClCASBFKACkCAWAFKEAkCIUAFKEAkCqu+4BhtI3YQ6njO5BTny6t+4RsAt2vLLRZdZjjwJAilAASBEKAClCASBFKACkCAWAFKEAkCIUAFKEAkCKUABIEQoAKUIBIEUoAKQIBYAUoQCQIhQAUoQCQIpQAEgRCgApQgEgRSgApAgFgBShAJAiFABShAJAilAASBEKAClCASBFKACkCAWAFKEAkCIUAFKEAkCKUABIEQoAKUIBIEUoAKQIBYAUoQCQIhQAUoQCQIpQAEgRCgApQgEgRSgApAgFgBShAJAiFABShAJAilB0yKTFC3TsimWads91dY+CYTjt3e/Sqsd+rMdX369PXzq/7nFqQyg6ZOutP9Dacz9X9xgYhq6uLn3pur/WGe8/V7977EydddYcveMdR9Y9Vi26q3pg20dJmi3pUEkhaZOkOyJiTVXbbLIXH1qtN014W91jYBhmnHCcnnhinZ588peSpFtuuV0feP9pWrNmbc2TdV4lexS2L5O0XJIlPSypt7h8s+3Lq9gmsLuNP/Rgrd+w6f+vb9i4WePHH1zjRPWpao/ifEnTIuLV1oW2vyhplaS/qWi7wG5j+zeWRUQNk9SvqmMUr0sav5PlhxS37ZTtebb7bPd9e/u6ikYDytm4YbMmTnjjf+MJhx6izZu31DhRfarao1gk6V7bayWtL5YdJmmKpAVD3SkilkpaKkl9E+aMzHSjMXr7VmjKlB5NmjRRGzc+pblzZ+tjfzwyX/moJBQRcbftt0uaof6DmZa0QVJvRLxWxTabrmfJJRpz0jHqHjdW03tv0KZrlmvr8nvqHgttvPbaa7po0Wd11/e+qVFdXVp207e0evV/1T1WLdzU51zsUexZTny6t+4RsAt2vLLxNw/E7ATnUQBIEQoAKUIBIEUoAKQIBYAUoQCQIhQAUoQCQIpQAEgRCgApQgEgRSgApAgFgBShAJAiFABShAJAilAASBEKAClCASBFKACkCAWAFKEAkCIUAFKEAkCKUABIEQoAKUIBIFUqFLYPtz2ruPwW22OqHQtAk6ShsP0JSbdJ+lqxaIKk71Q5FIBmKbNHMV/SKZJekKSIWCvpbVUOBaBZyoTifyPilYErtrslRXUjAWiaMqG4z/ZnJL3F9qmSbpX03WrHAtAkZUJxuaRnJD0q6QJJd0n6bJVDAWiW7myFiHhd0teLHwAj0JChsP2o2hyLiIjplUwEoHHa7VGc0bEpADTakKGIiP8euGz7YEkz1L+H0RsRT3VgNgANUeaEqz+T9LCkD0o6U9K/2f541YMBaI70YKakSyUdFxG/kiTbb5X0U0k3VjkYgOYo8/LoBknbWq5vk7S+mnEANFG7Vz0uKS5ulPSQ7dvVf4xitvqfigAYIdo99Rh4h+gTxc+A26sbB0ATtXvV46pODgKgudKDmbYPlPRpSdMk7TOwPCL+qMK5ADRImYOZ35D0uKQeSVdJWiept8KZADRMmVC8NSL+QdKrEXFfRHxc0okVzwWgQcqcR/Fq8Xuz7fdJ2qT+T7kCMEKUCcXVtveX9BeSvixprKSLK50KQKOUeZv5ncXF5yXNrHYcAE3U7oSrL6v928wXVjIRgMZpt0fR17EpsMd7edNP6h4BFWp3wtVNnRwEQHPxTWEAUoQCQIpQAEiV+YSrt9u+1/ZjxfXptvm4fmAEKbNH8XVJf6XiDM2IWCnp7CqHAtAsZUKxb0QM/qCaHVUMA6CZyoRiq+0jVJx8ZftMSZsrnQpAo5R5r8d8SUslHWV7o6QnJZ1b6VQAGqXMez1+IWmW7dGSuiJiW3YfAHuXMp9wdeWg65KkiPhcRTMBaJgyTz22t1zeR/1fNbimmnEANFGZpx7XtF63vVjSHZVNBKBxduXMzH0lTd7dgwBorjLHKB7VG59LMUrSgZI4PgGMIGWOUZzRcnmHpC0RwQlXwAjSNhS2uyR9LyKO6dA8ABqo7TGKiHhd0iO2D+vQPAAaqMxTj0MkrbL9sFpeKo2ID1Q2FYBGKRMKvoMUGOHKhOK9EXFZ6wLbfyvpvmpGAtA0Zc6jOHUny07f3YMAaK523+vx55I+JWmy7ZUtN42R9EDVgwFojnZPPb4p6fuSviDp8pbl2yLi2UqnAtAo7b7X43n1f43gOZ0bB0AT8SncAFKEAkCKUABIEQoAKUIBIEUoAKQIBYAUoQCQIhQAUoQCQIpQAEgRCgApQgEgRSgApAgFgBShAJAiFABShAJAilAASBEKAClCASBFKACkCAWAFKEAkCrzJcXYDSYtXqD9Zx2vHVuf16pZF9U9DkrYvOUZfebzi7X12efUZevM2afrY3Pn1D1WLQhFh2y99Qd6etld6rmWSOwpukeN0qUXfkJHT52i7dtf0tzzF+rkE47TET2H1z1ax/HUo0NefGi1dvz6xbrHwDAceMA4HT11iiRp9Oh9NfnwidryzK9qnqoeHQ+F7T/t9DaB39bGzVu0Zu0Tmj5tat2j1KKOPYqrhrrB9jzbfbb7vr19XQdHAob20ksv6+IrrtZlCy/QfqNH1z1OLSo5RmF75VA3STpoqPtFxFJJSyWpb8KcqGA0YFhe3bFDi664Wu9790yd+q5T6h6nNlUdzDxI0mmSnhu03JJ+WtE2gd0qInTlF67V5MMn6ryzP1j3OLWqKhR3StovIlYMvsH2jyraZqP1LLlEY046Rt3jxmp67w3adM1ybV1+T91joY2frVyl7959r448YpI+dN58SdJFF5ynPzh5Rs2TdZ4jmrmHz1OPPcuxK75Y9wjYBb9zwGSXWY+XRwGkCAWAFKEAkCIUAFKEAkCKUABIEQoAKUIBIEUoAKQIBYAUoQCQIhQAUoQCQIpQAEgRCgApQgEgRSgApAgFgBShAJAiFABShAJAilAASBEKAClCASBFKACkCAWAFKEAkCIUAFKEAkCKUABIEQoAKUIBIEUoAKQIBYAUoQCQIhQAUoQCQIpQAEgRCgApQgEgRSgApAgFgBShAJAiFABShAJAilAASBEKAClCASBFKACkCAWAlCOi7hlGHNvzImJp3XOgHP692KOoy7y6B8CwjPh/L0IBIEUoAKQIRT1G9PPdPdCI//fiYCaAFHsUAFKEooNsv8f2f9r+ue3L654H7dm+0fbTth+re5a6EYoOsT1K0t9LOl3S0ZLOsX10vVMhsUzSe+oeogkIRefMkPTziPhFRLwiabmk2TXPhDYi4seSnq17jiYgFJ1zqKT1Ldc3FMuAxiMUneOdLOMlJ+wRCEXnbJA0seX6BEmbapoFGBZC0Tm9ko603WP7TZLOlnRHzTMBpRCKDomIHZIWSPoXSWsk3RIRq+qdCu3YvlnSg5Km2t5g+/y6Z6oLZ2YCSLFHASBFKACkCAWAFKEAkCIUAFKEAinbLxa/x9u+LVl3ke19h7jtR7aPT+6/zvYBw5jtT2wvKbs+dg2hGKGKd7MOS0Rsiogzk9UWSdppKLDnIhR7GduTbD9u+ybbK23fNvAXvvhrfaXt+yV92PYRtu+2/e+2f2L7qGK9HtsP2u61/flBj/1YcXmU7cW2Hy22c6HthZLGS/qh7R8mc15vu8/2KttXDbr5UtsPFz9TivUPtP3PxUy9tk/Zff/VkCEUe6epkpZGxHRJL0j6VMtt/xMR74yI5er/LMgLI+L3Jf2lpK8U61wn6fqIOEHSU0NsY56kHknHFdv5RkR8Sf3vX5kZETOTGa+IiOMlTZf0h7ant9z2QkTMkLRE0rUtM/1dMdOHJN2QPD52I0Kxd1ofEQ8Ul/9J0jtbbvuWJNneT9LJkm61vULS1yQdUqxziqSbi8v/OMQ2Zkn6anFquiJiuJ/bMNf2f0j6maRp6v8wnwE3t/w+qWV7S4pZ75A01vaYYW4Tu6i77gFQicHn5bde31787pL064j4vZKPMZhLrLPzO9o96t+DOSEinrO9TNI+Q2x74HKXpJMi4uVBj7UrI2CY2KPYOx1me+Av8TmS7h+8QkS8IOlJ2x+WJPc7trj5AfW/u1WSPjrENv5V0idtdxf3H1cs3yYp+0s/Vv3Bet72Qer/eMBWZ7X8frBlewsGVrA9VOBQAUKxd1oj6TzbKyWNk3T9EOt9VNL5th+RtEpvfDTfRZLm2+6VtP8Q971B0i8lrSzu/5Fi+VJJ3293MDMiHlH/U45Vkm5Uf5havdn2Q8UcFxfLFko6vjhwulrSJ4d6fOx+vHt0L2N7kqQ7I+KYmkfBXoQ9CgAp9igApNijAJAiFABShAJAilAASBEKAClCASD1f/5NqNdmKvXLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matRent = confusion_matrix(y_predictedNB, y_true)\n",
    "sns.heatmap(matRent.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('predict label')\n",
    "plt.ylabel('true lable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix we could know the algorithm result is not same with my predict result. And different from the decision tree. I think I need to double check what's going wrong with the tree algorithorm code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the report and the confusion metris above we could know the precision of not Satisfied and the recall of Satisfied is 1. But the other two metrics are not good. So, in this decision tree, if the predict result is 0 we could believe that the person will be unsatisfied. But, if the predict result is 1, then there are wtil 25% probility that the person will be unsatisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found what's interesting is for the Naive Bayes model, even though we just use the rent to predict, the result is better than decision tree. So, for this situation, the Naive Bayes model is better than decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification Models ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the biggest difference between a generative model and a discriminative model is:  \n",
    "For discriminative model, when you get the P(y|x), you just need to know whether it's bigger or smaller than a threshold and then you can make a decision.  \n",
    "But for a generative model, you need to compare with all the P(x, y) and then choose the biggest feature as the predicted feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference:  \n",
    "https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-a-discriminative-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
